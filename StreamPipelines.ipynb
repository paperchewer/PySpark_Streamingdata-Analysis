{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LWcg_C-y8Mr",
        "outputId": "d776e072-2939-494d-af5d-7e076ffea211"
      },
      "source": [
        "sc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://DESKTOP-V18RQVR:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v2.4.5</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>PySparkShell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ],
            "text/plain": [
              "<SparkContext master=local[*] appName=PySparkShell>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhyO5oACy8Mw"
      },
      "source": [
        "from pyspark.streaming import StreamingContext\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql.functions import udf, struct, array, col, lit\n",
        "from pyspark.sql.types import StringType, DoubleType "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgNEVOZyy8M0"
      },
      "source": [
        "from pyspark.ml import Pipeline, PipelineModel\n",
        "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, CountVectorizer, StopWordsRemover\n",
        "from pyspark.ml.classification import NaiveBayes\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7EJkodHy8M3"
      },
      "source": [
        "path = 'C:/Users/tinhc/Desktop/data/myoutput-*'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOgOnSe5y8M6"
      },
      "source": [
        "path = 'data/myoutput-*'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYAfjnfby8M9"
      },
      "source": [
        "df = spark.read.json(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXDXhJxby8NA"
      },
      "source": [
        "from difflib import unified_diff\n",
        "\n",
        "def make_diff(df):\n",
        "    return '\\n'.join([ l for l in unified_diff(df.text_old.split('\\n'),df.text_new.split('\\n')) if l.startswith('+') or l.startswith('-') ])\n",
        "\n",
        "diff_udf = udf(make_diff, StringType())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9WXTIfAy8ND"
      },
      "source": [
        "#make the difference between text_old and text_new\n",
        "df = df.withColumn(\"diff\", diff_udf(\n",
        "    struct([df[x] for x in df.columns])\n",
        " ))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLwA-9tUy8NH",
        "outputId": "d95e8468-d922-4d61-fa98-4af27c05e53f"
      },
      "source": [
        "df.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- comment: string (nullable = true)\n",
            " |-- label: string (nullable = true)\n",
            " |-- name_user: string (nullable = true)\n",
            " |-- text_new: string (nullable = true)\n",
            " |-- text_old: string (nullable = true)\n",
            " |-- title_page: string (nullable = true)\n",
            " |-- url_page: string (nullable = true)\n",
            " |-- diff: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlGwA2qBy8NK",
        "outputId": "4d7793c9-bc7e-4d7c-ca4a-f77bb249ec99"
      },
      "source": [
        "df.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9677"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWIRUXhSy8NN",
        "outputId": "495a5596-2c28-4fcb-df87-308560cc420e"
      },
      "source": [
        "df.groupBy(\"label\").count().show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-----+\n",
            "| label|count|\n",
            "+------+-----+\n",
            "|  safe| 8235|\n",
            "|unsafe| 1339|\n",
            "|vandal|  103|\n",
            "+------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_cJ2ld_y8NQ"
      },
      "source": [
        "# process data: transforming labels into numbers 0,1,2\n",
        "#def labelTrans(df):\n",
        "#    if df.label == \"safe\": \n",
        " #       return 0\n",
        "#    elif df.lable == \"unsafe\":\n",
        "  #      return 1\n",
        " #   else: \n",
        " #       return 2\n",
        "#trans_udf = udf(labelTrans, DoubleType())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diwCfW6Uy8NT"
      },
      "source": [
        "#df = df.withColumn(\"type\", trans_udf(\n",
        "#    struct([df[x] for x in df.columns])\n",
        "# ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7b5JVavy8NV",
        "outputId": "e3fece77-6277-4374-dc62-db890dd5175d"
      },
      "source": [
        "df.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- comment: string (nullable = true)\n",
            " |-- label: string (nullable = true)\n",
            " |-- name_user: string (nullable = true)\n",
            " |-- text_new: string (nullable = true)\n",
            " |-- text_old: string (nullable = true)\n",
            " |-- title_page: string (nullable = true)\n",
            " |-- url_page: string (nullable = true)\n",
            " |-- diff: string (nullable = true)\n",
            " |-- type: double (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "vr9a3M2Dy8NX"
      },
      "source": [
        "need to do vectorizing features (TF-IDF) \n",
        "good document for transforming dataframe: \n",
        "https://hackersandslackers.com/transforming-pyspark-dataframes/\n",
        "https://towardsdatascience.com/5-ways-to-add-a-new-column-in-a-pyspark-dataframe-4e75c2fd8c08\n",
        "# for IDF\n",
        "https://datascienceplus.com/multi-class-text-classification-with-pyspark/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iz9VdLJZy8NY"
      },
      "source": [
        "df_new = df.withColumnRenamed(\"label\",\"category\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5GnlZMKy8Na"
      },
      "source": [
        "df_select = df_new.select(\"category\", \"diff\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hZsh_VOy8Nc"
      },
      "source": [
        "(train, test) = df_select.randomSplit([0.75, 0.25], seed=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xhCastky8Nf"
      },
      "source": [
        "# Creating Pipelines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fInfJU3jy8Nf"
      },
      "source": [
        "#TF-IDF Features (using a Hash function)\n",
        "tokenizer = Tokenizer(inputCol=\"diff\", outputCol=\"words\")\n",
        "stopwordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
        "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
        "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
        "label_stringIdx = StringIndexer(inputCol = \"category\", outputCol = \"label\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8Qnpdbpy8Nh"
      },
      "source": [
        "# Count vector Features +IDF \n",
        "countVectors = CountVectorizer(inputCol=\"filtered\", outputCol=\"cv\", vocabSize=10000, minDF=5)\n",
        "idf_cv = IDF(inputCol=\"cv\", outputCol=\"features\", minDocFreq=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59c3aVBTy8Nk"
      },
      "source": [
        "# Pipeline 1: TF-IDF + Logistic Regression \n",
        "lr = LogisticRegression(maxIter=10, regParam=0.01,elasticNetParam=0)\n",
        "lr_idf = Pipeline(stages=[tokenizer, stopwordsRemover, hashingTF, idf, label_stringIdx,lr])\n",
        "\n",
        "# fit the pipeline 1 in the training data: \n",
        "model1 = lr_idf.fit(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KQU37Ney8Nm"
      },
      "source": [
        "nb = NaiveBayes(smoothing=1,modelType=\"multinomial\")\n",
        "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=50, maxDepth = 4, maxBins=32)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNsWwDeCy8No"
      },
      "source": [
        "# Pipeline 2: TF-IDF + Naive-Bayes  \n",
        "nb = NaiveBayes(smoothing=1,modelType=\"multinomial\")\n",
        "nb_idf = Pipeline(stages=[tokenizer, stopwordsRemover, hashingTF, idf, label_stringIdx,nb])\n",
        "\n",
        "# fit the pipeline 2 in the training data: \n",
        "model2 = nb_idf.fit(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCMclul6y8Nq"
      },
      "source": [
        "# Pipeline 3: TF-IDF + RandomForest \n",
        "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=50, maxDepth = 4, maxBins=32)\n",
        "rf_idf = Pipeline(stages=[tokenizer, stopwordsRemover, hashingTF, idf, label_stringIdx,rf])\n",
        "\n",
        "# fit the pipeline 3 in the training data: \n",
        "model3 = rf_idf.fit(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBhUecCiy8Ns"
      },
      "source": [
        "# Pipeline 4: Counter-vector + IDF + Logistic Regression \n",
        "lr_vector = Pipeline(stages=[tokenizer, stopwordsRemover, countVectors, idf_cv, label_stringIdx,lr])\n",
        "\n",
        "# fit the pipeline 2 in the training data: \n",
        "model4 = lr_vector.fit(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QruyQcN7y8Nu"
      },
      "source": [
        "# Pipeline 5: Counter-vector + IDF  + Naive-Bayes \n",
        "nb_vector = Pipeline(stages=[tokenizer, stopwordsRemover, countVectors,idf_cv, label_stringIdx,nb])\n",
        "\n",
        "# fit the pipeline 2 in the training data: \n",
        "model5 = nb_vector.fit(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxaTT5l-y8Nx"
      },
      "source": [
        "# Pipeline 6: Counter-vector +IDF  + Random Forest \n",
        "rf_vector = Pipeline(stages=[tokenizer, stopwordsRemover, countVectors, idf_cv, label_stringIdx,rf])\n",
        "\n",
        "# fit the pipeline 2 in the training data: \n",
        "model6 = rf_vector.fit(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhJC_nLgy8Nz"
      },
      "source": [
        "# Measuring Model Performance "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3pSmVj8y8N0",
        "outputId": "05761096-53c9-497c-d238-331eda9e6f48"
      },
      "source": [
        "# pipelines of TF-IDF models \n",
        "prediction1 = model1.transform(test)\n",
        "selected1 = prediction1.select(\"prediction\", \"label\")\n",
        "\n",
        "prediction2 = model2.transform(test)\n",
        "selected2 = prediction2.select(\"prediction\", \"label\")\n",
        "\n",
        "prediction3 = model3.transform(test)\n",
        "selected3 = prediction3.select(\"prediction\", \"label\")\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
        "print(\"Model 1's performance is = \" + str(evaluator.evaluate(selected1)))\n",
        "print(\"Model 2's performance is = \" + str(evaluator.evaluate(selected2)))\n",
        "print(\"Model 3's performance is = \" + str(evaluator.evaluate(selected3)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 1's performance is = 0.8304872969596002\n",
            "Model 2's performance is = 0.7417742607246981\n",
            "Model 3's performance is = 0.8546438983756768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFQpwwWSy8N2",
        "outputId": "e51599f8-dcc8-4ab4-e7dd-caf8a2492299"
      },
      "source": [
        "# pipelines of Count-Vectors models \n",
        "prediction4 = model4.transform(test)\n",
        "selected4 = prediction4.select(\"prediction\", \"label\")\n",
        "\n",
        "prediction5 = model5.transform(test)\n",
        "selected5 = prediction5.select(\"prediction\", \"label\")\n",
        "\n",
        "prediction6 = model6.transform(test)\n",
        "selected6 = prediction6.select(\"prediction\", \"label\")\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
        "print(\"Model 4's performance is = \" + str(evaluator.evaluate(selected4)))\n",
        "print(\"Model 5's performance is = \" + str(evaluator.evaluate(selected5)))\n",
        "print(\"Model 6's performance is = \" + str(evaluator.evaluate(selected6)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 4's performance is = 0.8354852144939608\n",
            "Model 5's performance is = 0.7238650562265723\n",
            "Model 6's performance is = 0.8546438983756768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_uwkOQdy8N4"
      },
      "source": [
        "model3.save(\"bestModel\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}